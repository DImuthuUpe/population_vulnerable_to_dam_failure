{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4741f66",
   "metadata": {},
   "source": [
    "# Socioeconomic characteristics of at-risk populations impacted by the aging dam infrastructure in the USA - Who is facing the risk of potential dam failures? \n",
    "\n",
    "**Authors**: Jinwoo Park <sup>1,2</sup>, Shaowen Wang<sup>1,2,*</sup>, Courtney Flint <sup>3</sup>, Upmanu Lall <sup>4</sup><br>\n",
    "<sup>1</sup> Department of Geography and Geographic Information Science, University of Illinois Urbana-Champaign <br>\n",
    "<sup>2</sup> CyberGIS Center for Advanced Digital and Spatial Studies, University of Illinois Urbana-Champaign <br>\n",
    "<sup>3</sup> Department of Environment & Society,Utah State University <br>\n",
    "<sup>4</sup> Department of Earth & Environmental Engineering, Columbia University <br>\n",
    "<sup>*</sup> Correspondence: Shaowen Wang, shaowen@illinois.edu <br>\n",
    "\n",
    "Last Updated Date: June 15, 2023\n",
    "\n",
    "### Abstract:\n",
    "The dam infrastructure in the conterminous United States (CONUS) has exceeded its designed service lives to a large extent, posing an increased risk of failures that can cause catastrophic disasters with substantial economic and human losses. However, limited attention has been paid to the characteristics of at-risk populations, hindering adequate understanding and preparedness for emergency planning. Our study proposes a framework employing spatial metrics to discover where and whether socially vulnerable populations are more exposed to flood inundation risks induced by dam failures. By applying the framework to 345 dams in the CONUS, we found that characteristics of at-risk populations vary extensively across space. To better understand this spatial variability, we categorized the dams into five clusters based on at-risk population characteristics. Our findings reveal that dams in California and New England face particularly high consequential risks as their failure could impact socially vulnerable populations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c3875f",
   "metadata": {},
   "source": [
    "### Notebook Outline \n",
    "***Hyperlinks work only within the Jupuyter environment***\n",
    "\n",
    "* [On-the-fly analysis with CyberGIS-Compute](#CyberGIS-Compute)\n",
    "* [Overall characteristics of at-risk populations in the CONUS](#Overall)\n",
    "* [Clusters of dams per characteristics of the at-risk population](#Clusters)\n",
    "* [Spatial patterns of dam clusters](#Spatial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b1b78",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2fe8db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import numpy as np\n",
    "import matplotlib.patheffects as pe\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888794e",
   "metadata": {},
   "source": [
    "<hr id=\"CyberGIS-Compute\" />\n",
    "\n",
    "## 0. On-the-fly analysis with CyberGIS-Compute\n",
    "\n",
    "The following cell will allow users to run the proposed framework, which reveals the characteristics of the at-risk population to potential failures of aging dam infrastructure. Due to the computational intensity, CyberGIS-Compute will only allow running for one dam, while the actual analysis was conducted with a parallel computing approach. <br>\n",
    "\n",
    "**Note**: Detailed information of the proposed framework is available at <a href=\"./Local_Analysis_Multi_Scenario.ipynb\">a different notebook</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254fa467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cybergis_compute_client import CyberGISCompute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef119ae-6e95-4177-853f-587d49b202f8",
   "metadata": {},
   "source": [
    "<h4 style=\"color:red;\"> User Interaction Required </h4>\n",
    "\n",
    "- Run the two cells below \n",
    "- Click on \"Submit Job\" on the \"Your Job Status\" tabpage \n",
    "- Wait until Job is finished (20-25 mins)\n",
    "- Proceed to the next cell\n",
    "\n",
    "**Provide dam id on the National Inventory of Dams (NID) to the `dam_id` text box.** Then, click `Submit New Job`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce5ddb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cybergis = CyberGISCompute(url=\"cgjobsup.cigi.illinois.edu\", isJupyter=True, protocol=\"HTTPS\", port=443, suffix=\"v2\")\n",
    "cybergis.show_ui(defaultJob='population_vulnerable_to_dam_failure')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d325f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "When you see `JOB_ENDED` on `Your Job Status` tab, you can download your results on `Download Job Results` tab. <br>\n",
    "Once the files are downloaded, you can go to your home directory of Jupyter environment. You will see a folder name starting with `globus_download_`. Please enter the folder and find `Multi_F_Results` and `N_0` folders. The folder should have the following three files. \n",
    "* `Multi_F_fim.geojson`: GEOID of inundated and non-inundated regions\n",
    "* `Multi_F_lm.geojson`: Bivariate LISA result\n",
    "* `Multi_F_mi.geojson`: Bivariate Moran's I result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185c74c2-de8a-4834-96a4-808383e70806",
   "metadata": {},
   "source": [
    "Load (pre)computed sample results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccab978-ebcc-4e08-b2e9-d88524816436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cybergis.recentDownloadPath:\n",
    "    result_path = cybergis.recentDownloadPath\n",
    "else:\n",
    "    result_path = './sample_results'\n",
    "print(f\"Loading results from {result_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140d549-357e-4b0c-afc7-9782aaa5d949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_mi = gpd.read_file(os.path.join(result_path, 'Multi_F_Results', 'N_0', 'Multi_F_mi.geojson'))\n",
    "sample_lm = gpd.read_file(os.path.join(result_path, 'Multi_F_Results', 'N_0', 'Multi_F_lm.geojson'))\n",
    "sample_fim = gpd.read_file(os.path.join(result_path, 'Multi_F_Results', 'N_0', 'Multi_F_fim.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2655d3e-77fd-43e0-8e0e-b492fc76a0b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dam_id = 'CA10022' \n",
    "#dam_id = 'TX00018'\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 10))\n",
    "\n",
    "lisa_color = {'HH': 'red', 'LL': 'blue', 'HL': 'skyblue', 'LH': 'orange', 'Not_Sig': 'white'}\n",
    "boundary_gdf = gpd.GeoDataFrame([0], geometry=[sample_lm.unary_union])\n",
    "\n",
    "color_brewer = ['#9ecae1','#4292c6','#084594']\n",
    "cm = LinearSegmentedColormap.from_list('cb_', color_brewer, N=3)\n",
    "\n",
    "# Plot Inundation Risk from various dam failure scenarios\n",
    "sample_fim.plot('value', ax=axes[0], cmap=cm, alpha=0.8)\n",
    "sample_mi.plot(marker=\"*\", color='black', markersize=500, ax=axes[0])\n",
    "\n",
    "axes[0].set_title('\\n Inundation Risk', fontsize=18)\n",
    "axes[0].get_xaxis().set_visible(False)\n",
    "axes[0].get_yaxis().set_visible(False)\n",
    "\n",
    "# Plot Bivariate LISA\n",
    "'''\n",
    "# The title of each cell provides Bivariate Moran's I \n",
    "# Census block color codes:\n",
    "## Red: HH cluster (high inundation risk and high social vulnerability)\n",
    "## Skyblue: HL cluster (high inundation risk and low social vulnerability)\n",
    "## Orange: LH cluster (low inundation risk and high social vulnerability)\n",
    "## Blue: LL cluster (low inundation risk and low social vulnerability)\n",
    "'''\n",
    "\n",
    "plot_cols = ['POV150', 'NOHSDP']\n",
    "for idx, val in enumerate(plot_cols, start=1):\n",
    "    for key in lisa_color.keys():\n",
    "        sample_lm.loc[(sample_lm[f'LISA_{val}'] == key)].plot(ax=axes[idx], color=lisa_color[key], edgecolor='face', lw=0.3, legend=True)\n",
    "\n",
    "    boundary_gdf.boundary.plot(ax=axes[idx], lw=0.5, color='black')\n",
    "    sample_mi.plot(marker=\"*\", color='black', markersize=500, ax=axes[idx])\n",
    "    axes[idx].set_title(label=f\"{val}\\n(BV Moran's I: {round(sample_mi[f'MI_{val}'].values[0], 2)})\",\n",
    "                        fontsize=18)\n",
    "    \n",
    "    axes[idx].get_xaxis().set_visible(False)\n",
    "    axes[idx].get_yaxis().set_visible(False)\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e38c1fb",
   "metadata": {},
   "source": [
    "## Results of the pre-computed analysis \n",
    "\n",
    "Given the computational intensity of our work, this notebook will use the pre-computed results have been run on High-Performance Computing Resources (HPC). <br>\n",
    "The following cell will import results file (`mi`) that has Bivaraite Moran's I. In addition, we load `states` and `basins` file for plotting purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7686966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mi = gpd.read_file('./results/Multi_F_mi_all.geojson')\n",
    "mi_cols = [col for col in mi.columns.to_list() if col.startswith('MI')]\n",
    "mi = mi.fillna(0)\n",
    "\n",
    "state_lookup = pd.read_csv('./census_geometry/state_lookup.csv')\n",
    "\n",
    "states = gpd.read_file('./census_geometry/tl_2022_us_state.geojson')\n",
    "states = states.merge(state_lookup, left_on='STUSPS', right_on='Abbr')\n",
    "states = states.loc[states['ContiguousUS'] == 1]\n",
    "states = states.to_crs(epsg=4326)\n",
    "\n",
    "basins = gpd.read_file('./census_geometry/WBD_HU2.geojson')\n",
    "basins = basins[['states', 'huc2', 'name', 'geometry']]\n",
    "basins = basins.to_crs(epsg=4326)\n",
    "basins = gpd.clip(basins, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b890d98b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign HUC2 basin to each dam\n",
    "for idx, row in basins.iterrows():\n",
    "    mi.loc[mi['geometry'].within(row['geometry']), 'HUC2'] = row['huc2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b57a8",
   "metadata": {},
   "source": [
    "<hr id=\"Overall\" />\n",
    "\n",
    "## 1. Overall characteristics of at-risk populations in the CONUS\n",
    "\n",
    "The following cell conducts a two-tailed t-test (n: 345, degree of freedom: 344) and Bonferroni Correction, where the p-value is less than 0.00015 (i.e., 0.05 / 345 (the number of dams))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f8c93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mi_df = mi[[col for col in mi.columns if col.startswith('MI')]]\n",
    "\n",
    "for col in mi_df.columns:\n",
    "    mi_df = mi_df.loc[pd.notna(mi_df[col])]\n",
    "\n",
    "ttest_df = pd.DataFrame(data={'var': mi_df.columns.to_list()}, \n",
    "                        columns=['var', 'mean', 'std','coef', 'pval'])\n",
    "\n",
    "# Conduct T-test\n",
    "for col in mi_cols:\n",
    "    ttest_ = scipy.stats.ttest_1samp(mi_df[col], popmean=0)\n",
    "    ttest_df.loc[ttest_df['var'] == col, 'mean'] = mi_df[col].mean()\n",
    "    ttest_df.loc[ttest_df['var'] == col, 'std'] = mi_df[col].std()\n",
    "    ttest_df.loc[ttest_df['var'] == col, 'coef'] = ttest_[0]\n",
    "    ttest_df.loc[ttest_df['var'] == col, 'pval'] = ttest_[1]\n",
    "\n",
    "# Conduct Bonferroni Correction\n",
    "ttest_df['bonf'] = sm.stats.multipletests(ttest_df['pval'], 0.05, method='bonferroni')[0] \n",
    "ttest_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd35f59",
   "metadata": {},
   "source": [
    "Our analysis indicated that the potential failure of dams in the CONUS would affect the less socially vulnerable for most variables. Out of 16 census data units, nine variables (i.e., POV150, UNEMP, HBURD, NOHSDP, SNGPNT, LIMENG, MINRTY, MUNIT, and NOVEH) provided their means lower than 0 (i.e., negative spatial correlation) and were statistically significant. \n",
    "\n",
    "**Note**: \n",
    "* Histograms illustrate the distribution of Bivariate Moran’s I (i.e., spatial relationship between the risk of flood inundation and the social vulnerability for each census variable). <br>\n",
    "* Solid and dashed redlines represent the mean (μ) and ± one standard deviation (σ) for each distribution, respectively. \n",
    "* Black line represents the normal distribution with a mean of 0 and the same standard deviation as the data. \n",
    "* Title of each cell specifies whether the Bivariate Moran’s I distribution is statistically different from the normal distribution that has the same deviation (black curve line).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d9901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 4, figsize=(15,8))\n",
    "ax = axes.reshape(-1)\n",
    "\n",
    "binwidth = 0.025\n",
    "n = 10\n",
    "pvalue_list = [] # For Bonferroni Correction\n",
    "\n",
    "for idx, row in ttest_df.iterrows():\n",
    "    \n",
    "    bins = np.arange(math.floor(min(mi_df[row['var']]) * n) / n, math.ceil(max(mi_df[row['var']]) * n) / n + binwidth, binwidth)\n",
    "    \n",
    "    mi_df[row['var']].hist(ax=ax[idx], bins=bins, color='lightgrey')\n",
    "    \n",
    "    # Generate Normal Distribution with the mean of 0 and the same std. \n",
    "    ax2 = ax[idx].twinx()\n",
    "    mu, sigma = 0, mi_df[row['var']].std()\n",
    "    s = np.random.default_rng().normal(loc=0.0, scale=sigma, size=10000)\n",
    "    ax2.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
    "                 np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
    "                 linewidth=2, color='black')\n",
    "\n",
    "    ylim = ax[idx].get_ylim()[1]\n",
    "    ax[idx].vlines(0, 0, ylim, color='black')\n",
    "    ax[idx].vlines(mi_df[row['var']].mean(), 0, ylim, color='red')\n",
    "    ax[idx].vlines(mi_df[row['var']].mean() + mi_df[row['var']].std(), 0, ylim, color='red', linestyles='dashed')\n",
    "    ax[idx].vlines(mi_df[row['var']].mean() - mi_df[row['var']].std(), 0, ylim, color='red', linestyles='dashed')\n",
    "\n",
    "    if row['bonf'] == True:\n",
    "        if row['mean'] > 0:\n",
    "            label = 'Positive*'\n",
    "        else:\n",
    "            label = 'Negative*'\n",
    "    else:\n",
    "        label = 'Not Sigificant'\n",
    "    \n",
    "    ax[idx].set_title(label=f\"{row['var'].split('_')[1]} ({label})\", fontsize=20)\n",
    "    ax[idx].set_xlim(-0.5, 0.5)\n",
    "    ax[idx].get_yaxis().set_visible(False)\n",
    "    ax2.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c572ca9",
   "metadata": {},
   "source": [
    "<hr id=\"Clusters\" />\n",
    "\n",
    "## 2. Clusters of dams per characteristics of the at-risk population\n",
    "\n",
    "Our further analysis clusters dams by examining how many census variables exhibited positive or negative spatial correlation coefficients. This section proceeds with the following two steps: Principal Component Analysis (PCA) and K-Means clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4285ea",
   "metadata": {},
   "source": [
    "### 2.1. PCA for 16 Moran's I (Risk of inundation & SVI-related Census data)\n",
    "\n",
    "Principal Component Analysis (PCA) was employed to decrease the dimension of 16 Bivariate Moran's I to five principal components (PCs), explaining 73% of the original variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7321fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_n = 5\n",
    "pca = PCA(n_components=pca_n, svd_solver='full', random_state=17)\n",
    "pca_result = pca.fit_transform(mi_df)\n",
    "print(f'Explained variation per principal component: {pca.explained_variance_ratio_}')\n",
    "print(f'Cumulative variance explained by {pca_n} principal components: {round(np.sum(pca.explained_variance_ratio_), 2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2576ede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Results from pca.components_\n",
    "dataset_pca = pd.DataFrame(abs(pca.components_), columns=mi_df.columns, index=[f'PC_{v}' for v in range(1, pca_n+1)])\n",
    "pca_df = pd.DataFrame(pca_result, columns=[f\"Component_{v+1}\" for v in range(0, pca_n)])\n",
    "mi_df= pd.concat([mi_df, pca_df], axis=1)\n",
    "\n",
    "print(\"\\n*************** Most important features *************************\")\n",
    "for v in range(1, pca_n+1):\n",
    "    print(f'As per PC \\n', (dataset_pca[dataset_pca > 0.3].iloc[v-1]).sort_values(ascending=False).dropna())   \n",
    "print(\"\\n******************************************************************\")\n",
    "\n",
    "mi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457a5849",
   "metadata": {},
   "source": [
    "### 2.2. K-Means Clustering using PCA results\n",
    "\n",
    "K-means clustering took the six PCs and clustered them into five groups. Given that the clustering quality is subject to the number of clusters, we employed the Silhouette method; it identifies the optimal number that maximizes inter-cluster variation and minimizes intra-cluster variation. The five clusters provided the second-highest silhouette coefficient (0.1844), while the highest coefficient (0.2768) was obtained for the two clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6935f67b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def determine_number_of_cluster(array):\n",
    "    km_cost = []  # Sum of squared distances of samples to their closest cluster center.\n",
    "    distortions = []  # the average of the squared distances from the cluster centers of the respective clusters.Typically, the Euclidean distance metric is used.\n",
    "    km_silhouette = {}\n",
    "\n",
    "    for i in range(2, 11):\n",
    "        KM = KMeans(n_clusters=i, max_iter=999, n_init = 99, random_state=17)\n",
    "        KM.fit(array)\n",
    "\n",
    "        # Calculate Silhouette Scores\n",
    "        preds = KM.predict(array)\n",
    "        silhouette = silhouette_score(array, preds)\n",
    "        km_silhouette[i] = silhouette\n",
    "\n",
    "    print(max(km_silhouette, key=km_silhouette.get))\n",
    "        \n",
    "    return km_silhouette\n",
    "\n",
    "\n",
    "def kmeans_cluster(array, num_of_cluster):\n",
    "    kmeans = KMeans(n_clusters=num_of_cluster, max_iter=999, n_init = 99, random_state=17)\n",
    "    kmeans.fit(array)\n",
    "    y_kmeans = kmeans.predict(array)\n",
    "    \n",
    "    cluster_df = pd.DataFrame({'cluster': y_kmeans}, index=array.index)\n",
    "    cluster_df['cluster'] = cluster_df['cluster'].astype(str)\n",
    "    \n",
    "    return cluster_df\n",
    "\n",
    "\n",
    "# silhouette_scores = determine_number_of_cluster(mi_[plot_cols_mi])\n",
    "silhouette_scores = determine_number_of_cluster(mi_df[[f\"Component_{v+1}\" for v in range(0, pca_n)]])\n",
    "print({idx: round(val, 4) for idx, val in silhouette_scores.items()})\n",
    "\n",
    "# We select the second highest silhouette coefficient as the highest silhouette coefficient indicates only 2 groups. \n",
    "mi_copy = kmeans_cluster(mi_df[[f\"Component_{v+1}\" for v in range(0, pca_n)]], 5)\n",
    "mi['cluster'] = mi_copy['cluster']\n",
    "mi.replace({'cluster': {'1': 'A', '2': 'B', '0': 'C', '4': 'D', '3': 'E'}}, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "ax.bar(silhouette_scores.keys(), silhouette_scores.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f2f54a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.reshape(-1)\n",
    "\n",
    "# Class A: High vulnerability population - Red\n",
    "# Class B: Low vulnerability population - Blue\n",
    "# Class C: Partially low vulnerability (Poverty, Unemployment, Houseburden, Single Parent, \n",
    "#          Enlgihsh, Minority, MultiUnit, NoVehicle) - Lightblue\n",
    "# Class D: Mixture of vulnerability (High Elderly pop, Disability, Mobile home and \n",
    "#                                    Low Houseburden, Minority, Limited English) - Lightgreen\n",
    "# Class E: No Major Pattern - Grey\n",
    "\n",
    "PROPS = {'boxprops':{'facecolor':'#d3d3d3', 'edgecolor':'black'},\n",
    "         'medianprops':{'color':'red'},\n",
    "         'whiskerprops':{'color':'black'},\n",
    "         'capprops':{'color':'black'}\n",
    "        }\n",
    "\n",
    "for idx, c in enumerate(['A', 'B', 'C', 'D', 'E'], start=1):\n",
    "\n",
    "    temp_cluster = mi.loc[mi['cluster'] == c, \n",
    "                          [col for col in mi.columns if col.startswith('MI')]\n",
    "                         ].melt()\n",
    "    sns.boxplot(x = 'variable', y = 'value', data=temp_cluster, ax=axes[idx], showfliers=False, linewidth=0.75, **PROPS)\n",
    "\n",
    "    axes[idx].set_ylim(-0.5, 0.5)\n",
    "    axes[idx].set_yticks([v / 10 for v in range(-4, 5, 1)])\n",
    "    axes[idx].set_yticklabels([f\"{v / 10}\" for v in range(-4, 5, 1)], fontsize=12)\n",
    "    axes[idx].text(0.5, 1.01, f'Cluster {c} ({round(temp_cluster.shape[0]/16)} dams)', \n",
    "                 ha = 'center', va = 'bottom', fontsize=15, transform=axes[idx].transAxes)\n",
    "    axes[idx].axhline(0, color='black', linewidth=2)\n",
    "    axes[idx].yaxis.grid(True)\n",
    "#     axes[c].xaxis.grid(True)\n",
    "    \n",
    "    if (c == 'B') | (c == 'E'):\n",
    "        axes[idx].set_ylabel(\"Bivariate Moran's I\", fontsize=15)\n",
    "        axes[idx].yaxis.set_label_position(\"right\")\n",
    "        axes[idx].yaxis.tick_right()\n",
    "    else:\n",
    "        axes[idx].yaxis.set_tick_params(labelleft=False, left=False)\n",
    "        axes[idx].set_ylabel('')\n",
    "    \n",
    "    if (c == 'C') | (c == 'D') | (c == 'E'):\n",
    "        axes[idx].set_xlabel(\"Census Data\", fontsize=15)\n",
    "        axes[idx].set_xticklabels([col.split('_')[1] for col in mi.columns if col.startswith('MI')], \n",
    "                                  rotation = 'vertical', fontsize=12)\n",
    "    else:\n",
    "        axes[idx].set_xlabel('')\n",
    "        axes[idx].get_xaxis().set_visible(False)\n",
    "\n",
    "axes[0].get_xaxis().set_visible(False)\n",
    "axes[0].get_yaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2dc8a5",
   "metadata": {},
   "source": [
    "<hr id=\"Spatial\" />\n",
    "\n",
    "## 3. Spatial patterns of dam clusters\n",
    "\n",
    "Out of 345 dams, each cluster has the percentage as follows: Cluster A (19%), Cluster B (13 %), Cluster C (12 %), Cluster D (16 %), and Cluster E (40 %). In addition, we calculated the percentage of dams per cluster and hydrological unit region (HUC2). <br>\n",
    "Among 18 regions in the CONUS, 11 regions have more than five dams. Ohio River basin has the largest number (74 dams), followed by the Arkansas-White-Red region (50 dams). Out of 345 dams, Tennessee and Upper Colorado regions have 0 dams, and the following regions have five or fewer dams: Souris-Red-Rainy (5), Rio Grande (4), Lower Colorado (3), Great Lakes (2), and Great Basin (1). We excluded these regions for further analysis to avoid potential biased interpretation caused by insufficient dam counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b81db1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Class A: High vulnerability population - Red\n",
    "# Class B: Low vulnerability population - Blue\n",
    "# Class C: Partially low vulnerability (Poverty, Unemployment, Houseburden, Single Parent, \n",
    "#          Enlgihsh, Minority, MultiUnit, NoVehicle) - Lightblue\n",
    "# Class D: Mixture of vulnerability (High Elderly pop, Disability, Mobile home and \n",
    "#                                    Low Houseburden, Minority, Limited English) - Lightgreen\n",
    "# Class E: No Major Pattern - Grey\n",
    "\n",
    "mi_plot = mi.copy(deep=True)\n",
    "mi_plot = mi_plot.to_crs(epsg=5070)\n",
    "mi_plot['cluster'] = mi_plot['cluster'].astype(str)\n",
    "\n",
    "basins = basins.to_crs(epsg=5070)\n",
    "states = states.to_crs(epsg=5070)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "basins.boundary.plot(ax=ax, color='black', linewidth=1)\n",
    "states.boundary.plot(ax=ax, color='black', linewidth=0.1, linestyle='dashed')\n",
    "basins.apply(lambda x: ax.annotate(text='\\n'.join(x['name'].split(' ')[:-1]), \n",
    "                                   size=12, \n",
    "                                   xy=x.geometry.centroid.coords[0], \n",
    "                                   ha='center',\n",
    "                                   path_effects=[pe.withStroke(linewidth=2, foreground=\"white\")]\n",
    "                                  ),\n",
    "             axis=1)\n",
    "\n",
    "mi_plot.loc[mi_plot['cluster'] == 'A'].plot(ax=ax, color='red', markersize=15)  # Class A: High vulnerability population - Red\n",
    "mi_plot.loc[mi_plot['cluster'] == 'B'].plot(ax=ax, color='blue', markersize=15) # Class B: Low vulnerability population - Blue\n",
    "mi_plot.loc[mi_plot['cluster'] == 'C'].plot(ax=ax, color='lightblue', markersize=15)   # Class C: Partially low vulnerability - Lightblue\n",
    "mi_plot.loc[mi_plot['cluster'] == 'D'].plot(ax=ax, color='lightgreen', markersize=15)   # Class D: Mixture of vulnerability - Lightgreen\n",
    "mi_plot.loc[mi_plot['cluster'] == 'E'].plot(ax=ax, color='grey', markersize=15)   # Class E: No Major Pattern - Grey\n",
    "\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a275f5",
   "metadata": {},
   "source": [
    "Several hydrological unit regions provide a notable percentage for specific dam clusters. A significant portion of dams in Upper Mississippi (50%), California (44%), New England (36%), and Texas-Gulf (32%) regions were classified as Cluster A. <br>\n",
    "A substantial percentage of Cluster B dams (i.e., dams potentially affecting the less socially vulnerable) was observed in Missouri (36%) and Texas-Gulf (27%) regions. <br>\n",
    "Ohio and Arkansas-White-Red regions are the regions that have the largest and the second largest number of dams, but they provided a similar proportion of dams to the ones from 345 dams. In other words, most dams in these regions were classified as Cluster E. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66086bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huc2_regions = ['Pacific Northwest Region', 'Missouri Region', 'Upper Mississippi Region', \n",
    "                'Ohio Region', 'Mid Atlantic Region', 'California Region', \n",
    "                'Arkansas-White-Red Region', 'Texas-Gulf Region', 'Lower Mississippi Region', \n",
    "                'South Atlantic-Gulf Region', 'New England Region']\n",
    "\n",
    "fig, axes = plt.subplots(2, 6, figsize=(15, 5))\n",
    "axes = axes.reshape(-1)\n",
    "\n",
    "for idx, huc2_region in enumerate(huc2_regions, start=1):\n",
    "    huc2 = basins.loc[basins['name'] == huc2_region, 'huc2'].values[0]\n",
    "    huc2_mi = mi.loc[mi['HUC2'] == huc2]\n",
    "    print(f\"Basin Name: {huc2_region}, Associated Dam Counts: {huc2_mi.shape[0]}\")\n",
    "    \n",
    "    if huc2_mi.shape[0] > 5:\n",
    "        cluster_count = huc2_mi.groupby('cluster').count()\n",
    "        \n",
    "        for cluster in ['A', 'B', 'C', 'D', 'E']:\n",
    "            if not cluster in cluster_count.index:\n",
    "                temp_df = pd.DataFrame({'cluster': [cluster], 'ID': [0]})\n",
    "                temp_df = temp_df.set_index('cluster')\n",
    "                cluster_count = pd.concat([temp_df, cluster_count])\n",
    "        \n",
    "        cluster_count['count'] = cluster_count['ID']\n",
    "        cluster_count = cluster_count[['count']].reset_index()\n",
    "\n",
    "        cluster_count['percent'] = cluster_count['count'] / cluster_count['count'].sum()\n",
    "        cluster_count.sort_values('cluster', inplace=True)\n",
    "        cluster_count.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        cluster_count['percent'].plot.pie(colors=[\"red\", \"blue\", 'lightblue', 'lightgreen', 'grey'], \n",
    "                                          startangle=90,counterclock=False, \n",
    "                                          ax=axes[idx], shadow=True, labels=None, \n",
    "                                          autopct=lambda p: '{:.0f}%'.format(round(p)) if p > 0 else '', \n",
    "                                         )\n",
    "        \n",
    "        axes[idx].set_title(' '.join(huc2_region.split(' ')[:-1]), fontsize=14)\n",
    "        axes[idx].get_xaxis().set_visible(False)\n",
    "        axes[idx].get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "# Create a pie chart for overall dam ratio per cluster\n",
    "temp_df = pd.DataFrame({'cluster': ['A', 'B', 'C', 'D', 'E'], 'count': [67, 44, 41, 54, 139]})\n",
    "temp_df['count'].plot.pie(colors=[\"red\", \"blue\", 'lightblue', 'lightgreen', 'grey'], \n",
    "                 radius = 1 , \n",
    "                 startangle=90, counterclock=False, \n",
    "                 labels=None, ax=axes[0], shadow=True, \n",
    "                 autopct=lambda p: '{:.0f}%'.format(round(p)) if p > 0 else ''\n",
    "                )\n",
    "axes[0].set_title('Overall', fontsize=14)        \n",
    "axes[0].get_xaxis().set_visible(False)\n",
    "axes[0].get_yaxis().set_visible(False)\n",
    "        \n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ad8ba8",
   "metadata": {},
   "source": [
    "# Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iguide",
   "language": "python",
   "name": "iguide"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
